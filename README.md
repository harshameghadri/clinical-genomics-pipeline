# Clinical Genomics Pipeline v1.0.0

An open-source, fully reproducible workflow integrating genomics (DNA) and transcriptomics (RNA) analysis for clinical applications.

## ğŸ“‹ Overview

This Phase 1 foundation pipeline provides a complete, regulatory-compliant workflow for processing clinical genomic samples. Built with Nextflow and Apptainer, it offers:

- **DNA Analysis**: WGS/WES alignment, variant calling, structural variants, CNV detection  
- **RNA Analysis**: RNA-seq alignment, transcript quantification
- **Quality Control**: Comprehensive QC reports with FastQC and MultiQC
- **Metadata Management**: DuckDB-powered metadata tracking
- **GDPR Compliance**: Automated sample anonymization and PHI protection
- **Reproducibility**: Full version tracking, checksums, and containerization

## ğŸš€ Quick Start

### Prerequisites
- Nextflow â‰¥ 22.10.0
- Apptainer/Singularity
- Python 3.8+
- 16+ GB RAM, 32+ CPU cores recommended

### Installation

```bash
# Clone the repository
git clone <repository-url>
cd clinical-genomics-pipeline

# Build container images
./containers/build_containers.sh

# Setup test data
./data/test/download_test_data.sh

# Run tests
./tests/run_tests.sh

# Run pipeline with test data
./scripts/run_pipeline.sh --profile test
```

## ğŸ“ Project Structure

```
clinical-genomics-pipeline/
â”œâ”€â”€ main.nf                    # Main pipeline workflow
â”œâ”€â”€ nextflow.config            # Primary configuration
â”œâ”€â”€ configs/                   # Environment-specific configs
â”‚   â”œâ”€â”€ aws.config            # AWS Batch configuration  
â”‚   â”œâ”€â”€ slurm.config          # SLURM cluster configuration
â”‚   â””â”€â”€ test.config           # Test environment configuration
â”œâ”€â”€ modules/                   # Pipeline modules
â”‚   â”œâ”€â”€ dna/                  # DNA processing modules
â”‚   â”‚   â”œâ”€â”€ main.nf           # DNA pipeline workflow
â”‚   â”‚   â”œâ”€â”€ alignment.nf      # BWA-MEM2 alignment
â”‚   â”‚   â”œâ”€â”€ variants.nf       # DeepVariant calling
â”‚   â”‚   â”œâ”€â”€ structural_variants.nf # Manta SV detection
â”‚   â”‚   â””â”€â”€ cnv.nf            # CNVnator CNV detection
â”‚   â”œâ”€â”€ rna/                  # RNA processing modules  
â”‚   â”‚   â”œâ”€â”€ main.nf           # RNA pipeline workflow
â”‚   â”‚   â”œâ”€â”€ alignment.nf      # STAR alignment
â”‚   â”‚   â””â”€â”€ quantification.nf # Salmon quantification
â”‚   â”œâ”€â”€ qc/                   # Quality control modules
â”‚   â”‚   â”œâ”€â”€ fastqc.nf         # FastQC process
â”‚   â”‚   â””â”€â”€ multiqc.nf        # MultiQC reporting
â”‚   â””â”€â”€ metadata/             # Metadata management
â”‚       â”œâ”€â”€ duckdb.nf         # Database operations
â”‚       â”œâ”€â”€ checksums.nf      # File integrity
â”‚       â”œâ”€â”€ logging.nf        # Process logging  
â”‚       â””â”€â”€ gdpr.nf           # GDPR compliance
â”œâ”€â”€ containers/               # Apptainer definitions
â”‚   â”œâ”€â”€ base.def              # Base container
â”‚   â”œâ”€â”€ fastqc.def            # FastQC container
â”‚   â”œâ”€â”€ bwa_mem2.def          # BWA-MEM2 container
â”‚   â”œâ”€â”€ star.def              # STAR container
â”‚   â”œâ”€â”€ deepvariant.def       # DeepVariant container
â”‚   â”œâ”€â”€ salmon.def            # Salmon container
â”‚   â”œâ”€â”€ duckdb.def            # DuckDB container
â”‚   â””â”€â”€ build_containers.sh   # Build script
â”œâ”€â”€ data/                     # Data directory
â”‚   â””â”€â”€ test/                 # Test datasets
â”‚       â”œâ”€â”€ download_test_data.sh # Test data setup
â”‚       â”œâ”€â”€ dna_samples.csv   # DNA sample sheet
â”‚       â””â”€â”€ rna_samples.csv   # RNA sample sheet
â”œâ”€â”€ schemas/                  # Output schemas
â”‚   â””â”€â”€ output_schema.json    # Pipeline output schema
â”œâ”€â”€ scripts/                  # Utility scripts
â”‚   â””â”€â”€ run_pipeline.sh       # Pipeline runner
â”œâ”€â”€ tests/                    # Unit tests
â”‚   â”œâ”€â”€ test_modules.py       # pytest test suite
â”‚   â”œâ”€â”€ requirements.txt      # Test dependencies
â”‚   â””â”€â”€ run_tests.sh          # Test runner
â””â”€â”€ docs/                     # Documentation
    â”œâ”€â”€ CONFIGURATION.md      # Configuration guide
    â”œâ”€â”€ DEPLOYMENT.md         # Deployment guide
    â””â”€â”€ TROUBLESHOOTING.md    # Troubleshooting guide
```

## ğŸ”§ Configuration

### Basic Parameters

```bash
# Input files
--dna_samples     CSV file with DNA sample information  
--rna_samples     CSV file with RNA sample information
--reference       Reference genome directory

# Resources  
--threads         Number of CPU threads (default: 16)
--memory          Memory allocation (default: 32.GB)
--outdir          Output directory (default: ./results)

# Analysis options
--deepvariant_model    DeepVariant model type (WGS/WES)
--min_variant_quality  Minimum variant quality score (default: 20)
--anonymize_samples    Enable GDPR compliance (default: true)
```

### Sample Sheet Format

**DNA samples (dna_samples.csv):**
```csv
sample_id,fastq_1,fastq_2,sample_type
SAMPLE001,/path/to/R1.fastq.gz,/path/to/R2.fastq.gz,DNA
```

**RNA samples (rna_samples.csv):**
```csv  
sample_id,fastq_1,fastq_2,sample_type
SAMPLE001,/path/to/R1.fastq.gz,/path/to/R2.fastq.gz,RNA
```

## ğŸ–¥ï¸ Execution Profiles

### Local Execution
```bash
./scripts/run_pipeline.sh --profile local
```

### SLURM Cluster
```bash  
./scripts/run_pipeline.sh --profile slurm --params-file my_params.json
```

### AWS Batch
```bash
./scripts/run_pipeline.sh --profile aws --params-file aws_params.json
```

### Test Profile
```bash
./scripts/run_pipeline.sh --profile test
```

## ğŸ“Š Outputs

### Directory Structure
```
results/
â”œâ”€â”€ alignments/           # BAM alignment files
â”‚   â”œâ”€â”€ dna/             # DNA alignments (BWA-MEM2)
â”‚   â””â”€â”€ rna/             # RNA alignments (STAR)
â”œâ”€â”€ variants/            # Variant call files
â”‚   â”œâ”€â”€ dna/             # SNP/indel variants (DeepVariant)
â”‚   â”œâ”€â”€ structural/      # Structural variants (Manta)  
â”‚   â””â”€â”€ cnv/             # Copy number variants (CNVnator)
â”œâ”€â”€ quantification/      # Gene expression (Salmon)
â”œâ”€â”€ qc/                  # Quality control reports
â”‚   â”œâ”€â”€ fastqc/          # FastQC individual reports
â”‚   â””â”€â”€ multiqc_report.html # Consolidated QC report
â”œâ”€â”€ metadata/            # Pipeline metadata
â”‚   â”œâ”€â”€ pipeline_metadata.duckdb # Metadata database
â”‚   â”œâ”€â”€ checksums/       # File integrity checksums
â”‚   â””â”€â”€ logs/            # Processing logs
â””â”€â”€ reports/             # Execution reports
    â”œâ”€â”€ execution_report.html
    â”œâ”€â”€ timeline.html
    â””â”€â”€ pipeline_dag.svg
```

### Key Output Files

**DNA Analysis:**
- `{sample}.sorted.bam` - Aligned reads (BWA-MEM2)
- `{sample}.vcf.gz` - Variant calls (DeepVariant)
- `{sample}.gvcf.gz` - Genomic variant calls
- `{sample}.manta.vcf.gz` - Structural variants (Manta)
- `{sample}.cnv.txt` - Copy number variants (CNVnator)

**RNA Analysis:**  
- `{sample}.Aligned.sortedByCoord.out.bam` - Aligned reads (STAR)
- `{sample}_salmon/quant.sf` - Transcript quantification (Salmon)

**Quality Control:**
- `multiqc_report.html` - Comprehensive QC report
- `{sample}_fastqc.html` - Individual FastQC reports

**Metadata:**
- `pipeline_metadata.duckdb` - Queryable metadata database
- `{sample}.checksums.txt` - File integrity checksums
- `anonymization_map.json` - GDPR anonymization mapping (secure storage)

## ğŸ”’ GDPR Compliance

The pipeline includes comprehensive GDPR compliance features:

- **Automatic Anonymization**: Sample IDs are hashed using SHA256
- **PHI Detection**: Scans file names for potential personal information
- **Secure Mapping**: Original-to-anonymous ID mapping for authorized access
- **Data Retention**: Configurable retention policies
- **Audit Logging**: Complete processing audit trail

### Data Subject Rights

The pipeline supports GDPR data subject rights:
- Right to access: Contact your data controller
- Right to rectification: Contact your data controller  
- Right to erasure: Contact your data controller
- Right to portability: Data provided in standard formats (VCF, BAM, JSON)

## ğŸ§ª Testing

### Run Test Suite
```bash
./tests/run_tests.sh
```

### Unit Tests
```bash  
cd tests
python -m pytest test_modules.py -v --cov=../modules
```

### Integration Test
```bash
./scripts/run_pipeline.sh --profile test
```

## ğŸ“ˆ Performance Optimization

### Resource Recommendations

**Small Scale (1-10 samples):**
- CPU: 16-32 cores
- Memory: 32-64 GB  
- Storage: 1-5 TB

**Medium Scale (10-50 samples):**
- CPU: 32-64 cores
- Memory: 64-128 GB
- Storage: 5-25 TB

**Large Scale (50-100+ samples):**
- CPU: 64+ cores  
- Memory: 128+ GB
- Storage: 25+ TB
- Consider cluster/cloud deployment

### Performance Tuning

1. **Adjust thread allocation** per process type
2. **Optimize memory** for alignment steps
3. **Use local SSD storage** for work directory
4. **Enable resume** for interrupted runs
5. **Tune container caching** for repeated runs

## ğŸ› Troubleshooting

### Common Issues

**Container Build Failures:**
```bash  
# Clean and rebuild
rm -rf containers/*.sif
./containers/build_containers.sh
```

**Memory Issues:**
```bash
# Reduce resource allocation
--max_memory '64.GB' --max_cpus 16
```

**Permission Errors:**
```bash
# Check file permissions
chmod -R 755 data/
chmod +x scripts/*.sh containers/*.sh tests/*.sh
```

**SLURM Job Failures:**
```bash
# Check cluster configuration
squeue -u $USER
sinfo -p genomics
```

For detailed troubleshooting, see [TROUBLESHOOTING.md](docs/TROUBLESHOOTING.md).

## ğŸ“š Documentation

- [Configuration Guide](docs/CONFIGURATION.md) - Detailed configuration options
- [Deployment Guide](docs/DEPLOYMENT.md) - HPC and cloud deployment  
- [Troubleshooting Guide](docs/TROUBLESHOOTING.md) - Common issues and solutions

## ğŸ¤ Contributing

1. Fork the repository
2. Create feature branch (`git checkout -b feature/amazing-feature`)
3. Run tests (`./tests/run_tests.sh`)
4. Commit changes (`git commit -m 'Add amazing feature'`)
5. Push to branch (`git push origin feature/amazing-feature`)
6. Open Pull Request

## ğŸ“„ License

This project is licensed under the Apache License 2.0 - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- **GIAB Consortium** - Reference datasets
- **ENCODE Project** - RNA-seq reference data  
- **nf-core Community** - Best practices and inspiration
- **Nextflow Team** - Workflow orchestration framework
- **Apptainer Team** - Container runtime

## ğŸ“ Support

- **Issues**: [GitHub Issues](https://github.com/your-org/clinical-genomics-pipeline/issues)
- **Discussions**: [GitHub Discussions](https://github.com/your-org/clinical-genomics-pipeline/discussions)
- **Email**: genomics-support@your-institution.org

---

**Pipeline Version**: 1.0.0  
**Last Updated**: 2024-01-01  
**Compatibility**: Nextflow â‰¥ 22.10.0, Apptainer â‰¥ 1.0.0